{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import sys\n",
    "import time\n",
    "import transforms3d as tf\n",
    "from PIL import Image\n",
    "import sys\n",
    "sys.path.append(\"/home/chichu/Desktop/PoseEstimation-main/real_robot\")\n",
    "import pyrealsense2 as rs\n",
    "from real_robot.utils.realsense import RealSenseAPI\n",
    "from real_robot.utils.camera import depth2xyz, transform_points\n",
    "\n",
    "realsense = RealSenseAPI(preset=\"High Accuracy\",\n",
    "                         depth_option_kwargs={\n",
    "                             rs.option.exposure: 1500\n",
    "                         })\n",
    "color_image, depth_image = realsense.capture()\n",
    "\n",
    "color_image.dtype, color_image.shape, depth_image.shape\n",
    "\n",
    "def getHM(r,t):\n",
    "\n",
    "    if(np.shape(r)==(3,1)):\n",
    "        rmat,_ = cv2.Rodrigues(r)\n",
    "        hm  = np.concatenate((rmat, t), axis=1)\n",
    "        HM = np.concatenate((hm,[[0,0,0,1]]),axis=0)\n",
    "    else:\n",
    "        hm  = np.concatenate((r, t), axis=1)\n",
    "        HM = np.concatenate((hm,[[0,0,0,1]]),axis=0)\n",
    "\n",
    "    return HM\n",
    "\n",
    "def getPose(HM,unit):\n",
    "    rmat = HM[0:3,0:3]\n",
    "    tvec = HM[0:3,3]\n",
    "    Position = [0,0,0]\n",
    "\n",
    "    Angles = tf.euler.mat2euler(rmat)\n",
    "    Angles = np.array(Angles) *57.2958  #sxyz\n",
    "    # Cube position from translation vector\n",
    "    if unit == \"mm\":\n",
    "        Position[0] = tvec[0]  * 1000  \n",
    "        Position[1]=  tvec[1]  * 1000   \n",
    "        Position[2]=  tvec[2]  * 1000\n",
    "    elif unit == \"cm\":\n",
    "        Position[0] = tvec[0]  * 100  \n",
    "        Position[1]=  tvec[1]  * 100   \n",
    "        Position[2]=  tvec[2]  * 100\n",
    "    Quaternion = tf.quaternions.mat2quat(rmat)  #wxyz\n",
    "    Position = np.array(Position).round(3)\n",
    "    Quaternion = np.array(Quaternion).round(3)\n",
    "    Angles = Angles.round(0)\n",
    "    return Position,Quaternion, Angles\n",
    "\n",
    "\n",
    "\n",
    "def pose_estimation(frame, aruco_dict,size, matrix_coefficients, distortion_coefficients,Translations,Rotations):\n",
    "\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    dict = cv2.aruco.getPredefinedDictionary(aruco_dict)\n",
    "    parameters = cv2.aruco.DetectorParameters()\n",
    "    detector = cv2.aruco.ArucoDetector(dict,parameters)\n",
    "    \n",
    "    corners, ids, rejected = detector.detectMarkers(gray)\n",
    "\n",
    "    objPoints = [[-size/2,size/2,0],[size/2,size/2,0],[size/2,-size/2,0],[-size/2,-size/2,0]]\n",
    "    op = np.array(objPoints).reshape(4,1,3)\n",
    "    shape = np.shape(corners)\n",
    "\n",
    "    #no markers detected\n",
    "    if shape[0] == 0:\n",
    "        return frame,False,None\n",
    "    corners = np.array(corners)\n",
    "\n",
    "   \n",
    "    # Choose the lowest id ArUco\n",
    "    minId = min(ids)[0]\n",
    "    minIndex = np.argmin(ids)\n",
    "    if minId > 5 :\n",
    "        return frame,False,None\n",
    "    \n",
    "    #vectors from camera to marker Tc_c2m\n",
    "    _, rvec, tvec = cv2.solvePnP(op,corners[minIndex], matrix_coefficients,distortion_coefficients,flags=cv2.SOLVEPNP_IPPE_SQUARE)\n",
    "    frame = cv2.drawFrameAxes(frame, matrix_coefficients, distortion_coefficients, rvec, tvec, 0.03,2)\n",
    "\n",
    "    #Cam2Marker\n",
    "    HM_cam2marker = getHM(rvec,tvec)\n",
    "\n",
    "    #Hand-Eye Calibration Result Base to Camera\n",
    "    HeC_b2c = np.load(\"/home/chichu/Desktop/PoseEstimation-main/real_robot/hec_camera_poses/Tb_b2c_20230726_CSE4144_front.npy\")\n",
    "    \n",
    "    #base to marker\n",
    "    HM_base2marker = np.matmul(HeC_b2c,HM_cam2marker)\n",
    "    t1 = HM_base2marker\n",
    "\n",
    "    \n",
    "    zero = np.array([0,0,0],dtype=float)\n",
    "    zero = zero.reshape(3,1)\n",
    "    \n",
    "\n",
    "    # Marker to Marker0 (rotation only)\n",
    "    HM_marker2marker0 =  getHM(Rotations[minId],zero)\n",
    "    \n",
    "    #base to Marker0\n",
    "    HM_base2marker0 = np.matmul(HM_base2marker,HM_marker2marker0)\n",
    "\n",
    "    #Marker0 to Cube\n",
    "    translation = Translations[minId]\n",
    "    translation = translation.reshape(3,1)\n",
    "    HM_marker02cube = getHM(zero,translation)\n",
    "    \n",
    "    #base to Cube\n",
    "    HM_base2cube = np.matmul(HM_base2marker0,HM_marker02cube)\n",
    "\n",
    "    return frame, True, HM_base2cube\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "aruco_type = cv2.aruco.DICT_4X4_100\n",
    "arucoParams = cv2.aruco.DetectorParameters()\n",
    "\n",
    "#real sense\n",
    "intrinsic_camera = np.array(((601.44104,0., 428.31464),(0., 601.37744, 241.95168),(0,0,1)))\n",
    "distortion = np.array((0.,0.,0.,0.))\n",
    "\n",
    "# Rotation Dict\n",
    "Rotations= {\n",
    "\t0 : np.array([[1,0,0],[0,1,0],[0,0,1]],dtype=float),    #default\n",
    "\t1 : np.array([[0,0,1],[0,1,0],[-1,0,0]],dtype=float),   #y+90\n",
    "\t2 : np.array([[-1,0,0],[0,1,0],[-0,0,-1]],dtype=float), #y+180\n",
    "    3 : np.array([[-0,0,-1],[0,1,0],[1,0,-0]],dtype=float), #y-90\n",
    "\t4 : np.array([[1,0,0],[0,0,-1],[0,1,0]],dtype=float),   #x+90\n",
    "\t5 : np.array([[1,0,0],[0,0,1],[0,-1,0]],dtype=float),   #x-90\n",
    "}\n",
    "\n",
    "\n",
    "# Translations Dict\n",
    "cube_len = 0.04\n",
    "Translations={\n",
    "    0 : np.array([[0,0,-cube_len/2]],dtype=float),\n",
    "    1 : np.array([[cube_len/2,0,0]],dtype=float),\n",
    "    2 : np.array([[0,0,cube_len/2]],dtype=float),\n",
    "    3 : np.array([[-cube_len/2,0,0]],dtype=float),\n",
    "    4 : np.array([[0,-cube_len/2,0]],dtype=float),\n",
    "    5 : np.array([[0,cube_len/2,0]],dtype=float)\n",
    "}\n",
    "\n",
    "cv2.namedWindow(\"show\", cv2.WINDOW_NORMAL)\n",
    "while True:\n",
    "    img, depth_image = realsense.capture()\n",
    "\n",
    "\n",
    "    img, retval, HM_base2cube = pose_estimation(img, aruco_type, 0.036, intrinsic_camera, distortion,Translations,Rotations)\n",
    "    \n",
    "    \n",
    "    if retval:\n",
    "        HM_base2cube  = np.array(HM_base2cube )\n",
    "        Position, Quaternion, Angles = getPose(HM_base2cube,\"cm\")\n",
    "        \n",
    "        print(Position, Quaternion, Angles)\n",
    "        \n",
    "\n",
    "    cv2.imshow('show', img)\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if key == ord('q'):\n",
    "        break\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
